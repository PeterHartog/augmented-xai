_target_: representation.src.models.transformer_cnn.TransformerCNN
src_vocab_size: 68
num_encoder_layers: 3
emb_size: 512
num_heads: 8
num_feedforward: 2
dim_feedforward: 512
norm: layer
activation: relu
skip_connection: false
weight_sharing: false
max_sep_feedforward: false
emb_dropout: 0.1
enc_dropout: 0.1
output_dim: 2
batch_first: true
mask_hidden_state: true
vector_embed: false
learnable_positional_encoding: false
lr: 0.0001
weight_decay: 0.01
freeze_encoder: false
need_attention_weights: true
average_attention_weights: true
max_seq_len: null
init_method: xavier_init
cnn_dropout: 0.1
kernel_sizes:
- 1
- 2
- 3
- 4
- 5
- 6
- 7
- 8
- 9
- 10
- 15
- 20
filters:
- 100
- 200
- 200
- 200
- 200
- 100
- 100
- 100
- 100
- 100
- 160
- 160
highway_kernel: 1
stride: 1
